{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b715b0f7",
   "metadata": {},
   "source": [
    "# Load Tensorflow and check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a3b996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 15:29:27.964303: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-30 15:29:27.964366: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-30 15:29:27.993625: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-30 15:29:28.057744: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-30 15:29:29.190164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 15:29:33.834267: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-30 15:29:34.131901: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-30 15:29:34.135391: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-30 15:29:34.319368: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-30 15:29:34.320790: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-30 15:29:34.322041: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-30 15:29:34.323592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 1974 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.core.dtypes import common as com\n",
    "from core.loader import Loader\n",
    "from models.model_wrapper import ModelWrapper\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "for device in device_lib.list_local_devices():\n",
    "    print(device.physical_device_desc)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TODO: Zkusit 3 stupnÄ› na NN, SVM a porovnat s LightGBM + XGBoost\n",
    "\n",
    "# 4 x Malware\n",
    "# 4x  Phishing\n",
    "# + DGA (jeden stupen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1258a0e",
   "metadata": {},
   "source": [
    "# Load input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17229825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #############################################################\n",
    "# EDIT this to specify benign / malicious datasets to use     #\n",
    "# #############################################################\n",
    "benign_dataset_filenames = [\n",
    "    'parkets/benign/benign_2312_anonymized_HTML.parquet', \n",
    "    'parkets/benign/umbrella_benign_FINISHED_HTML.parquet'\n",
    "        \n",
    "]\n",
    "malicious_dataset_filenames = [\n",
    "    'parkets/phishing_2406_strict_HTML.parquet'\n",
    "]\n",
    "\n",
    "# lex-dga-830k-pick.parquet LABEL je jmeno rodiny\n",
    "#  'parkets/malware_2406_strict_HTML.parquet'\n",
    "\n",
    "\n",
    "# #############################################################\n",
    "# EDIT this for to set appropriate labels (malware, dga, ...) #\n",
    "# #############################################################\n",
    "benign_label = \"benign\"\n",
    "malicious_label = \"phishing\"\n",
    "# #############################################################\n",
    "\n",
    "class_map = {benign_label: 0, malicious_label: 1}\n",
    "# print labels from malicious datasets\n",
    "\n",
    "loader = Loader(benign_dataset_filenames, malicious_dataset_filenames, benign_label=benign_label, malicious_label=malicious_label, subsample=1.0)\n",
    "df = loader.load()\n",
    "\n",
    "# dump columns names to text file\n",
    "\n",
    "\n",
    "# use scaler to scale the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe133857",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('columns.txt', 'w') as f:\n",
    "    for col in df.columns:\n",
    "        f.write(f\"{col}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee8986",
   "metadata": {},
   "source": [
    "### Generate subsets of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b073c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poli/Desktop/git/deep_domain_detection/src/core/segmenter.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/segmenter.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/segmenter.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/segmenter.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/segmenter.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/segmenter.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/segmenter.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n"
     ]
    }
   ],
   "source": [
    "from core.loader import Segmenter\n",
    "\n",
    "# Define the aggregates that needs to be created\n",
    "\n",
    "aggregates = [\n",
    "    [\"lex_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"geo_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"tls_\", \"geo_\", \"rdap_\"],\n",
    "]\n",
    "\n",
    "segmenter = Segmenter(df)\n",
    "segmenter.create_base_subsets() # create base subsets\n",
    "segmenter.create_aggregated_subsets(aggregates)\n",
    "subset_dfs = segmenter.get_aggregated_subsets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d5e75",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09378879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training XGBoost on 'lex_agg' features...\n",
      "Saving as stage: stage_1\n",
      "âœ… Accuracy for 'lex_agg': 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     81671\n",
      "           1       0.96      0.83      0.89     16404\n",
      "\n",
      "    accuracy                           0.97     98075\n",
      "   macro avg       0.96      0.91      0.93     98075\n",
      "weighted avg       0.96      0.97      0.96     98075\n",
      "\n",
      "\n",
      "ðŸš€ Training XGBoost on 'lex_+dns_+ip_+geo_agg' features...\n",
      "Saving as stage: stage_2\n",
      "âœ… Accuracy for 'lex_+dns_+ip_+geo_agg': 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     81671\n",
      "           1       0.98      0.95      0.96     16404\n",
      "\n",
      "    accuracy                           0.99     98075\n",
      "   macro avg       0.98      0.97      0.98     98075\n",
      "weighted avg       0.99      0.99      0.99     98075\n",
      "\n",
      "\n",
      "ðŸš€ Training XGBoost on 'lex_+dns_+ip_+tls_+geo_+rdap_agg' features...\n",
      "Saving as stage: stage_3\n",
      "âœ… Accuracy for 'lex_+dns_+ip_+tls_+geo_+rdap_agg': 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     81671\n",
      "           1       0.99      0.98      0.99     16404\n",
      "\n",
      "    accuracy                           1.00     98075\n",
      "   macro avg       0.99      0.99      0.99     98075\n",
      "weighted avg       1.00      1.00      1.00     98075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "model_wrapper = ModelWrapper(model_dir=\"models\")\n",
    "ARCH_NAME = \"XgBoost\"\n",
    "VERSION = \"v1.2\"\n",
    "\n",
    "# Dictionary to store XGBoost models and their performance metrics\n",
    "xgb_models = {}\n",
    "xgb_performance = {}\n",
    "\n",
    "params = {        \n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"sampling_method\": \"gradient_based\",\n",
    "    \"max_depth\": 12, \n",
    "    \"eta\": 0.09787878787878787, \n",
    "    \"min_child_weight\": 1, \n",
    "    \"subsample\": 0.595959595959596, \n",
    "    \"alpha\": 0, \n",
    "    \"gamma\": 0.06060606060606061, \n",
    "    \"lambda\": 2.0707070707070705, \n",
    "    \"max_delta_step\": 0, \n",
    "    \"grow_policy\": \"depthwise\",\n",
    "    \"max_bin\": 512,\n",
    "    \"n_estimators\": 600, \n",
    "    #\"scale_pos_weight\": scale_pos_weight,\n",
    "    \"random_state\": 42  # Set the seed for each run\n",
    "}\n",
    "\n",
    "for prefix, subset_df in subset_dfs.items():\n",
    "    print(f\"\\nðŸš€ Training XGBoost on '{prefix}' features...\")\n",
    "    \n",
    "    X = subset_df.drop('label', axis=1)\n",
    "    y = subset_df['label'].map(class_map)\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model = XGBClassifier(**params)\n",
    "    \n",
    "    # Fit the model\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "      \n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "\n",
    "    model_wrapper.save(xgb_model, arch_name=ARCH_NAME, label=malicious_label, prefix=f\"{prefix}\", version=VERSION)\n",
    "\n",
    "    \n",
    "    xgb_models[prefix] = xgb_model\n",
    "    \n",
    "    \n",
    "    xgb_performance[prefix] = {\n",
    "        'accuracy': acc,\n",
    "        'classification_report': report,\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Accuracy for '{prefix}': {acc:.2f}\")\n",
    "    print(report)\n",
    "    \n",
    "        # shap analysis\n",
    "    import shap\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create a SHAP explainer\n",
    "    explainer = shap.Explainer(xgb_model, X_train)\n",
    "    shap_values = explainer(X_test)\n",
    "    shap.summary_plot(shap_values, X_test, feature_names=X.columns)\n",
    "    plt.savefig(f\"shap_summary_{ARCH_NAME}_{malicious_label}_{prefix}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327e565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training LightGBM on 'lex_agg' features...\n",
      "[LightGBM] [Info] Number of positive: 148021, number of negative: 734653\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.327186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4012\n",
      "[LightGBM] [Info] Number of data points in the train set: 882674, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.167696 -> initscore=-1.602044\n",
      "[LightGBM] [Info] Start training from score -1.602044\n",
      "Saving as stage: stage_1\n",
      "âœ… LightGBM model accuracy for 'lex_agg': 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     81671\n",
      "           1       0.94      0.76      0.84     16404\n",
      "\n",
      "    accuracy                           0.95     98075\n",
      "   macro avg       0.95      0.88      0.91     98075\n",
      "weighted avg       0.95      0.95      0.95     98075\n",
      "\n",
      "\n",
      "ðŸš€ Training LightGBM on 'lex_+dns_+ip_+geo_agg' features...\n",
      "[LightGBM] [Info] Number of positive: 148021, number of negative: 734653\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11904\n",
      "[LightGBM] [Info] Number of data points in the train set: 882674, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.167696 -> initscore=-1.602044\n",
      "[LightGBM] [Info] Start training from score -1.602044\n",
      "Saving as stage: stage_2\n",
      "âœ… LightGBM model accuracy for 'lex_+dns_+ip_+geo_agg': 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     81671\n",
      "           1       0.96      0.90      0.93     16404\n",
      "\n",
      "    accuracy                           0.98     98075\n",
      "   macro avg       0.97      0.95      0.96     98075\n",
      "weighted avg       0.98      0.98      0.98     98075\n",
      "\n",
      "\n",
      "ðŸš€ Training LightGBM on 'lex_+dns_+ip_+tls_+geo_+rdap_agg' features...\n",
      "[LightGBM] [Info] Number of positive: 148021, number of negative: 734653\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16137\n",
      "[LightGBM] [Info] Number of data points in the train set: 882674, number of used features: 176\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.167696 -> initscore=-1.602044\n",
      "[LightGBM] [Info] Start training from score -1.602044\n",
      "Saving as stage: stage_3\n",
      "âœ… LightGBM model accuracy for 'lex_+dns_+ip_+tls_+geo_+rdap_agg': 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     81671\n",
      "           1       0.98      0.96      0.97     16404\n",
      "\n",
      "    accuracy                           0.99     98075\n",
      "   macro avg       0.99      0.98      0.98     98075\n",
      "weighted avg       0.99      0.99      0.99     98075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model_wrapper = ModelWrapper(model_dir=\"models\")\n",
    " \n",
    "# Dictionary to store LightGBM models and their performance metrics\n",
    "lgb_models = {}\n",
    "lgb_performance = {}\n",
    "\n",
    "ARCH_NAME = \"Lgbm\"\n",
    "VERSION = \"v1.2\"\n",
    "\n",
    "# Iterate through each subset, train LightGBM, and evaluate it\n",
    "for prefix, subset_df in subset_dfs.items():\n",
    "    print(f\"\\nðŸš€ Training LightGBM on '{prefix}' features...\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X = subset_df.drop('label', axis=1)\n",
    "    y = subset_df['label']\n",
    "    \n",
    "    \n",
    "    # map benign to 0 and malicious to 1\n",
    "    y = y.map(class_map)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Initialize and train LightGBM with hyperparameter tuning\n",
    "    lgb_model = LGBMClassifier(\n",
    "        objective='binary', \n",
    "        metric='binary_logloss', \n",
    "        learning_rate=0.05, \n",
    "        num_leaves=31, \n",
    "        max_depth=-1, \n",
    "        n_estimators=250, \n",
    "        subsample=0.8, \n",
    "        colsample_bytree=0.8, \n",
    "        reg_alpha=0.1, \n",
    "        reg_lambda=0.1\n",
    "    )\n",
    "    \n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # save the model \n",
    "    model_wrapper.save(lgb_model, arch_name=ARCH_NAME, label=malicious_label, prefix=f\"{prefix}\", version=VERSION)\n",
    "    \n",
    "    # Store the model\n",
    "    lgb_models[prefix] = lgb_model\n",
    "    \n",
    "    # Predict and evaluate the model\n",
    "    y_pred = lgb_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Store performance\n",
    "    lgb_performance[prefix] = {\n",
    "        'accuracy': acc,\n",
    "        'classification_report': report\n",
    "    }\n",
    "    \n",
    "    # Print performance\n",
    "    print(f\"âœ… LightGBM model accuracy for '{prefix}': {acc:.2f}\")\n",
    "    print(report)\n",
    "    \n",
    "    # shap analysis\n",
    "    import shap\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create a SHAP explainer\n",
    "    explainer = shap.Explainer(lgb_model, X_train)\n",
    "    shap_values = explainer(X_test)\n",
    "    shap.summary_plot(shap_values, X_test, feature_names=X.columns)\n",
    "    plt.savefig(f\"shap_summary_{ARCH_NAME}_{malicious_label}_{prefix}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
