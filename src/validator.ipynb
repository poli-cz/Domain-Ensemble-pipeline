{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 23:55:12.821117: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-27 23:55:12.821152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-27 23:55:12.850166: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-27 23:55:12.915963: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-27 23:55:14.052879: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 23:55:19.363243: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 23:55:19.669383: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 23:55:19.672266: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 23:55:19.804500: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 23:55:19.805941: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 23:55:19.807256: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 23:55:19.808467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 2045 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.core.dtypes import common as com\n",
    "from core.loader import Loader\n",
    "from models.model_wrapper import ModelWrapper\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "for device in device_lib.list_local_devices():\n",
    "    print(device.physical_device_desc)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TODO: Zkusit 3 stupnÄ› na NN, SVM a porovnat s LightGBM + XGBoost\n",
    "\n",
    "# 4 x Malware\n",
    "# 4x  Phishing\n",
    "# + DGA (jeden stupen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tabulate in /home/poli/.local/lib/python3.10/site-packages (0.8.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_saved_split(stage, label, folder=\"./data/\"):\n",
    "    filename = \"\"\n",
    "    if stage == 1:\n",
    "        filename = f\"validation_stage_1_{label}\"\n",
    "    elif stage == 2:\n",
    "        filename = f\"validation_stage_2_{label}\"\n",
    "    elif stage == 3:\n",
    "        filename = f\"validation_stage_3_{label}\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid stage. Choose 1, 2, or 3.\")\n",
    "    with open(f'{folder}{filename}.pkl', \"rb\") as f:\n",
    "        dump = pickle.load(f)\n",
    "        X_test = dump[\"X_test\"]\n",
    "        y_test = dump[\"Y_test\"]\n",
    "    return X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import os \n",
    "import joblib\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, confusion_matrix, classification_report,\n",
    "    accuracy_score, precision_score, recall_score, roc_auc_score\n",
    ")\n",
    "\n",
    "\n",
    "class ModelValidator:\n",
    "    \"\"\"\n",
    "    A class for validating machine learning models with various metrics.\n",
    "\n",
    "    Attributes:\n",
    "        model (estimator): The machine learning model to be validated.\n",
    "        X_test (array-like): The test dataset features.\n",
    "        y_test (array-like): The true labels corresponding to X_test.\n",
    "        arch_name (str): Optional architecture name for logging and file naming.\n",
    "        label (str): Optional label (e.g., 'malware', 'phishing') for context.\n",
    "        prefix (str): Optional prefix for versioning stages.\n",
    "        version (str): Optional version identifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, X_test, y_test, arch_name=None, label=None, prefix=None, version=None):\n",
    "        \"\"\"\n",
    "        Initializes the ModelValidator.\n",
    "\n",
    "        Parameters:\n",
    "           model (estimator): The trained machine learning model.\n",
    "           X_test (array-like): Features from the test dataset.\n",
    "           y_test (array-like): True labels for the test dataset.\n",
    "           arch_name (str): Model architecture name (optional).\n",
    "           label (str): Dataset label name (optional).\n",
    "           prefix (str): Stage prefix (optional).\n",
    "           version (str): Model version (optional).\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        # New attributes for naming\n",
    "        self.arch_name = arch_name\n",
    "        self.label = label\n",
    "        self.prefix = prefix\n",
    "        self.version = version\n",
    "        self.matrix_folder = 'confusion'\n",
    "        self.tex_path = \"./tex_sources/evaluation_metrics.tex\"  # â† force the folder and path!\n",
    "\n",
    "        # Create the folder immediately (safe even if it already exists)\n",
    "        os.makedirs(os.path.dirname(self.tex_path), exist_ok=True)\n",
    "    \n",
    "\n",
    "    def evaluate_performance(self):\n",
    "        \"\"\"\n",
    "        Evaluates and prints the model's performance metrics, including F1 score,\n",
    "        confusion matrix, and a classification report. Also saves a confusion matrix plot.\n",
    "        \"\"\"\n",
    "        print(\"\\nðŸ” Starting model evaluation...\")\n",
    "        \n",
    "        def svm_convert(df):\n",
    "            df = df.fillna(0)\n",
    "            df = df.replace({True: 1, False: 0})\n",
    "            return np.array(df)\n",
    "                \n",
    "                \n",
    "        ### Variable preprocessing for different architectures and models ###\n",
    "        if self.arch_name == 'feedforward':\n",
    "            # progres emoji\n",
    "            print(f\"ðŸ”„ Detected Neural network, using: {self.label} scaler\")\n",
    "            if self.label == 'malware':\n",
    "                self.X_test = joblib.load(f\"scalers/malware_scaler.joblib\").transform(self.X_test)\n",
    "            elif self.label == 'phishing':\n",
    "                self.X_test = joblib.load(f\"scalers/phishing_scaler.joblib\").transform(self.X_test)\n",
    "        \n",
    "        elif self.arch_name == 'svm':\n",
    "            print(f\"ðŸ”„ Detected SVM, using: {self.label} scaler\")\n",
    "            if self.label == 'malware':\n",
    "                self.X_test = joblib.load(f\"scalers/malware_scaler.joblib\").transform(self.X_test)\n",
    "            elif self.label == 'phishing':\n",
    "                self.X_test = joblib.load(f\"scalers/phishing_scaler.joblib\").transform(self.X_test)\n",
    "                \n",
    "            self.X_test = svm_convert(self.X_test)\n",
    "\n",
    "        \n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "        # --- Safe prediction processing ---\n",
    "        # Handle probability outputs (e.g., from neural networks)\n",
    "        if np.issubdtype(y_pred.dtype, np.floating):\n",
    "            if y_pred.ndim == 2 and y_pred.shape[1] > 1:\n",
    "                # Multiclass or binary with probabilities -> argmax\n",
    "                y_pred = np.argmax(y_pred, axis=1)\n",
    "            else:\n",
    "                # Single probability output -> threshold at 0.5\n",
    "                y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(self.y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(self.y_test, y_pred)\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "        fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "        tpr = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "\n",
    "        # --- Compute standard metrics ---\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        precision = precision_score(self.y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(self.y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # ROC AUC needs probability scores; fallback if not available\n",
    "        try:\n",
    "            if hasattr(self.model, \"predict_proba\"):\n",
    "                y_proba = self.model.predict_proba(self.X_test)[:, 1]\n",
    "            else:\n",
    "                y_proba = y_pred  # fallback if no probabilities\n",
    "            roc_auc = roc_auc_score(self.y_test, y_proba)\n",
    "        except Exception:\n",
    "            roc_auc = 0.0\n",
    "            \n",
    "                # --- Collect all metrics now ---\n",
    "        metrics = {\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1,\n",
    "            \"ROC AUC\": roc_auc,\n",
    "            \"True Negatives (TN)\": tn,\n",
    "            \"False Positives (FP)\": fp,\n",
    "            \"False Negatives (FN)\": fn,\n",
    "            \"True Positives (TP)\": tp,\n",
    "            \"False Positive Rate (FPR)\": fpr,\n",
    "            \"True Positive Rate (TPR)\": tpr,\n",
    "        }\n",
    "            \n",
    "            \n",
    "        # Pretty table print\n",
    "        self.print_ascii_table(metrics)\n",
    "\n",
    "        # Append LaTeX table\n",
    "        self.append_latex_table(metrics)\n",
    "\n",
    "        print(\"\\nðŸ“ Classification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred, digits=6))\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        self.plot_confusion_matrix(y_pred)\n",
    "        \n",
    "    def print_ascii_table(self, metrics_dict):\n",
    "        \"\"\"\n",
    "        Prints a nicely formatted ASCII table of metrics.\n",
    "        \"\"\"\n",
    "        headers = [\"Metric\", \"Value\"]\n",
    "        rows = [(k, v) for k, v in metrics_dict.items()]\n",
    "        table = tabulate(rows, headers=headers, tablefmt=\"grid\", floatfmt=\".4f\")\n",
    "        print(\"\\nðŸ“‹ Evaluation Summary:\")\n",
    "        print(table)\n",
    "\n",
    "    def append_latex_table(self, metrics_dict):\n",
    "        \"\"\"\n",
    "        Appends a polished LaTeX table of metrics to the specified .tex file.\n",
    "        Creates the file if it doesn't exist.\n",
    "        \"\"\"\n",
    "        # No need to create folder here anymore â€” already done in __init__\n",
    "\n",
    "        # Custom mapping for Czech + English metric names\n",
    "        metric_names = {\n",
    "            \"Accuracy\": \"PÅ™esnost (Accuracy)\",\n",
    "            \"F1 Score\": \"F1 SkÃ³re\",\n",
    "            \"Precision\": \"Precision (PÅ™esnost)\",\n",
    "            \"Recall\": \"Recall (Ãšplnost)\",\n",
    "            \"ROC AUC\": \"ROC AUC\",\n",
    "            \"True Negatives (TN)\": \"True Negatives (TN)\",\n",
    "            \"False Positives (FP)\": \"False Positives (FP)\",\n",
    "            \"False Negatives (FN)\": \"False Negatives (FN)\",\n",
    "            \"True Positives (TP)\": \"True Positives (TP)\",\n",
    "            \"False Positive Rate (FPR)\": \"False Positive Rate (FPR)\",\n",
    "            \"True Positive Rate (TPR)\": \"True Positive Rate (TPR)\",\n",
    "        }\n",
    "\n",
    "        table_rows = \"\"\n",
    "        for k, v in metrics_dict.items():\n",
    "            nice_name = metric_names.get(k, k)\n",
    "            table_rows += f\"{nice_name} & \\\\texttt{{{v:.4f}}} \\\\\\\\\\n\"\n",
    "\n",
    "        section_name = f\"{self.arch_name or 'Model'} {self.prefix or ''} {self.label or ''} {self.version or ''}\".strip()\n",
    "\n",
    "        latex_table = (\n",
    "            f\"\\\\section*{{VÃ½sledky hodnocenÃ­: {section_name}}}\\n\"\n",
    "            \"\\\\begin{table}[h!]\\n\"\n",
    "            \"\\\\centering\\n\"\n",
    "            \"\\\\begin{tabular}{|l|c|}\\n\"\n",
    "            \"\\\\hline\\n\"\n",
    "            \"\\\\textbf{Metrika} & \\\\textbf{Hodnota} \\\\\\\\\\n\"\n",
    "            \"\\\\hline\\n\"\n",
    "            f\"{table_rows}\"\n",
    "            \"\\\\hline\\n\"\n",
    "            \"\\\\end{tabular}\\n\"\n",
    "            f\"\\\\caption{{VÃ½sledky klasifikace modelu {section_name}}}\\n\"\n",
    "            f\"\\\\label{{tab:{(self.label or 'model').lower()}_{(self.arch_name or 'model').lower()}}}\\n\"\n",
    "            \"\\\\end{table}\\n\\n\"\n",
    "        )\n",
    "\n",
    "        with open(self.tex_path, \"a\") as f:\n",
    "            f.write(latex_table)\n",
    "\n",
    "        print(f\"ðŸ“„ Metrics table appended to {self.tex_path}\")\n",
    "\n",
    "\n",
    "    def plot_confusion_matrix(self, y_pred):\n",
    "        # Attempt to get classes dynamically\n",
    "        try:\n",
    "            classes = self.model.classes_\n",
    "        except AttributeError:\n",
    "            classes = np.unique(self.y_test)\n",
    "\n",
    "        cm = confusion_matrix(self.y_test, y_pred, labels=classes)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Reds)\n",
    "        plt.title('Confusion Matrix', fontsize=18)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45, fontsize=14)\n",
    "        plt.yticks(tick_marks, classes, fontsize=14)\n",
    "\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "        thresh = cm_norm.max() / 2.\n",
    "        for i, j in np.ndindex(cm.shape):\n",
    "            plt.text(j, i, f\"{cm_norm[i, j]:.4f}\\n({cm_norm[i, j]*100:.2f}%)\",\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"black\" if cm_norm[i, j] > thresh else \"black\", fontsize=16)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label', fontsize=14)\n",
    "        plt.xlabel('Predicted label', fontsize=14)\n",
    "\n",
    "        # Save the plot using your naming convention\n",
    "        if all(v is not None for v in [self.arch_name, self.prefix, self.label, self.version]):\n",
    "            filename = f\"{self.arch_name}_{self.prefix}_{self.label}_{self.version}_confusion_matrix.png\"\n",
    "        else:\n",
    "            filename = \"confusion_matrix.png\"\n",
    "\n",
    "        os.makedirs(self.matrix_folder, exist_ok=True)\n",
    "        save_path = os.path.join(self.matrix_folder, filename)\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        print(f\"ðŸ–¼ï¸ Confusion matrix plot saved to: {save_path}\\n\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading model from models/XgBoost_stage_3_malware_v1.1.xgb\n",
      "\n",
      "ðŸ” Starting model evaluation...\n",
      "\n",
      "ðŸ“‹ Evaluation Summary:\n",
      "+---------------------------+------------+\n",
      "| Metric                    |      Value |\n",
      "+===========================+============+\n",
      "| True Negatives (TN)       | 81489.0000 |\n",
      "+---------------------------+------------+\n",
      "| False Positives (FP)      |   154.0000 |\n",
      "+---------------------------+------------+\n",
      "| False Negatives (FN)      |   357.0000 |\n",
      "+---------------------------+------------+\n",
      "| True Positives (TP)       |  9714.0000 |\n",
      "+---------------------------+------------+\n",
      "| False Positive Rate (FPR) |     0.0019 |\n",
      "+---------------------------+------------+\n",
      "| True Positive Rate (TPR)  |     0.9646 |\n",
      "+---------------------------+------------+\n",
      "| F1 Score                  |     0.9744 |\n",
      "+---------------------------+------------+\n",
      "ðŸ“„ Metrics table appended to evaluation_metrics.tex\n",
      "\n",
      "ðŸ“ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.995638  0.998114  0.996874     81643\n",
      "           1   0.984394  0.964552  0.974372     10071\n",
      "\n",
      "    accuracy                       0.994428     91714\n",
      "   macro avg   0.990016  0.981333  0.985623     91714\n",
      "weighted avg   0.994403  0.994428  0.994403     91714\n",
      "\n",
      "ðŸ–¼ï¸ Confusion matrix plot saved to: confusion/XgBoost_stage_3_malware_v1.1_confusion_matrix.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_wrapper = ModelWrapper(model_dir=\"models\")\n",
    "ARCH_NAME = \"XgBoost\" \n",
    "#ARCH_NAME = \"Lgbm\"\n",
    "#ARCH_NAME = \"feedforward\"\n",
    "VERSION = \"v1.1\"\n",
    "#VERSION = \"v1.0\"\n",
    "malicious_label = \"malware\"\n",
    "stage = 3\n",
    "\n",
    "# combination\n",
    "# TODO: solve scalers for NN for each stage\n",
    "\n",
    "model = model_wrapper.load(arch_name=ARCH_NAME, label=malicious_label, prefix=f\"stage_{stage}\", version=VERSION)\n",
    "x_test, y_test = load_saved_split(3, malicious_label, folder=\"./data/\")\n",
    "\n",
    "validator = ModelValidator(model, x_test, y_test, arch_name=ARCH_NAME, label=malicious_label, prefix=f\"stage_{stage}\", version=VERSION)\n",
    "validator.evaluate_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading model from models/feedforward_stage_1_malware_v1.1.keras\n",
      "ðŸ”„ Detected Neural network, using: malware scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poli/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 62 features, but StandardScaler is expecting 176 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m load_saved_split(stage, malicious_label)\n\u001b[1;32m     11\u001b[0m validator \u001b[38;5;241m=\u001b[39m ModelValidator(model, x_test, y_test, arch_name\u001b[38;5;241m=\u001b[39marchitecture, label\u001b[38;5;241m=\u001b[39mmalicious_label, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39mVERSION)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [4], line 36\u001b[0m, in \u001b[0;36mModelValidator.evaluate_performance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ”„ Detected Neural network, using: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m scaler\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalware\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscalers/malware_scaler.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphishing\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscalers/phishing_scaler.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1043\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1040\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1042\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m-> 1043\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 62 features, but StandardScaler is expecting 176 features as input."
     ]
    }
   ],
   "source": [
    "# combination\n",
    "architectures = [\"feedforward\", \"XgBoost\", \"Lgbm\", \"svm\"]\n",
    "malicious_labels = [\"malware\", \"phishing\"]\n",
    "stages = [1, 2, 3]\n",
    "\n",
    "for architecture in architectures:       \n",
    "    for malicious_label in malicious_labels:\n",
    "        for stage in stages:\n",
    "            model = model_wrapper.load(arch_name=architecture, label=malicious_label, prefix=f\"stage_{stage}\", version=VERSION)\n",
    "            x_test, y_test = load_saved_split(stage, malicious_label)\n",
    "            validator = ModelValidator(model, x_test, y_test, arch_name=architecture, label=malicious_label, prefix=f\"stage_{stage}\", version=VERSION)\n",
    "            validator.evaluate_performance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
