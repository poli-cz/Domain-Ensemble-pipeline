{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da08d06-be0d-468a-bd17-d7bcba74880a",
   "metadata": {},
   "source": [
    "## Columns to be removed from training/validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b715b0f7",
   "metadata": {},
   "source": [
    "# Load Tensorflow and check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12a3b996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 12:47:42.569354: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 12:47:42.576653: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 12:47:42.580690: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 12:47:42.607271: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 12:47:42.611696: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 12:47:42.617013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 2043 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.core.dtypes import common as com\n",
    "from core.loader import Loader\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "for device in device_lib.list_local_devices():\n",
    "    print(device.physical_device_desc)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee8986",
   "metadata": {},
   "source": [
    "### Load subset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c39ab84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 3 skupiny grafů \n",
    "\n",
    "# 1. Samotné subsety - DONE \n",
    "    # phish\n",
    "    # malware\n",
    "    \n",
    "# 2. Agregace (jen agregované subsety)\n",
    "    # phish\n",
    "    # malware\n",
    "    \n",
    "# 3. Staged (3-4 fáze)\n",
    "    # phish\n",
    "\n",
    "BACKUP_FILE = './tmp/phishing_aggregated.pickle'\n",
    "\n",
    "def save_to_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {filename}.\")\n",
    "    \n",
    "    # save all the models \n",
    "    \n",
    "\n",
    "def load_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Data loaded from {filename}.\")\n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `results_grids` and `best_models` are the data you want to save.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b71e21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from ./tmp/phishing_aggregated.pickle.\n"
     ]
    }
   ],
   "source": [
    "loaded_data = load_from_pickle(BACKUP_FILE)\n",
    "results_grids = loaded_data['results_grids']\n",
    "top3_models = loaded_data['top3_models']\n",
    "subset_dfs = loaded_data['subset_dfs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8d161",
   "metadata": {},
   "source": [
    "### Visualize top models and overall results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ba51849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_165708/3184947395.py:49: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting best F1 Scores and top models\n",
    "best_f1_scores = []\n",
    "model_names = []\n",
    "subsets = []\n",
    "top_models = {}\n",
    "\n",
    "counter = 0\n",
    "for prefix, grid in results_grids.items():\n",
    "    # rename prefix to numbering\n",
    "    prefix = f'{counter+1}'\n",
    "    counter += 1\n",
    "    # Best F1 score\n",
    "    best_f1 = grid['F1'].max()\n",
    "    best_f1_scores.append(best_f1)\n",
    "    \n",
    "    # Top 3 models\n",
    "    top_3_models = grid.nlargest(3, 'F1')[['Model', 'F1']]\n",
    "    top_models[prefix] = top_3_models\n",
    "    model_names.append(top_3_models.iloc[0]['Model'])\n",
    "    subsets = [s.replace('_html', '') for s in subsets]\n",
    "    \n",
    "    subsets.append(prefix)\n",
    "    \n",
    "# remove html from subsets\n",
    "\n",
    "\n",
    "# Initialize figure\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "\n",
    "\n",
    "# Plot 3: Ranking of Models Across All Feature Sets\n",
    "model_rankings = pd.concat([grid[['Model', 'F1']] for grid in results_grids.values()])\n",
    "mean_f1_by_model = model_rankings.groupby('Model')['F1'].mean().sort_values(ascending=True)\n",
    "plt.subplot(1, 3, 3)\n",
    "bars = plt.barh(mean_f1_by_model.index, mean_f1_by_model, color='salmon')\n",
    "plt.title('Průměrné F1 skóre')\n",
    "plt.xlabel('F1')\n",
    "# Annotate exact average F1 scores\n",
    "for bar, score in zip(bars, mean_f1_by_model):\n",
    "    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{score:.4f}', va='center')\n",
    "    \n",
    "# save to pdf\n",
    "plt.savefig('average_f1_models.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13171490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting tikzplotlib\n",
      "  Downloading tikzplotlib-0.10.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /home/poli/.local/lib/python3.10/site-packages (from tikzplotlib) (3.7.2)\n",
      "Requirement already satisfied: numpy in /home/poli/.local/lib/python3.10/site-packages (from tikzplotlib) (1.24.3)\n",
      "Requirement already satisfied: Pillow in /home/poli/.local/lib/python3.10/site-packages (from tikzplotlib) (10.0.1)\n",
      "Collecting webcolors (from tikzplotlib)\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/poli/.local/lib/python3.10/site-packages (from matplotlib>=1.4.0->tikzplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/poli/.local/lib/python3.10/site-packages (from matplotlib>=1.4.0->tikzplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/poli/.local/lib/python3.10/site-packages (from matplotlib>=1.4.0->tikzplotlib) (4.37.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/poli/.local/lib/python3.10/site-packages (from matplotlib>=1.4.0->tikzplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/poli/.local/lib/python3.10/site-packages (from matplotlib>=1.4.0->tikzplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=1.4.0->tikzplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->tikzplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->tikzplotlib) (1.16.0)\n",
      "Downloading tikzplotlib-0.10.1-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: webcolors, tikzplotlib\n",
      "Successfully installed tikzplotlib-0.10.1 webcolors-24.11.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tikzplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d88e830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lex__agg', 'lex_+dns_+ip__agg', 'lex_+dns_+ip_+geo__agg', 'lex_+dns_+ip_+tls_+geo__agg', 'lex_+dns_+ip_+tls_+geo_+rdap__agg', 'lex_+dns_+ip_+tls_+geo_+rdap_+html__agg'])\n",
      "\\begin{table}[ht]\n",
      "  \\centering\n",
      "  \\caption{Feature‐subset label lookup}\n",
      "  \\begin{tabular}{llrr}\n",
      "    \\toprule\n",
      "    Label & Key & \\# features & \\# samples \\\\\n",
      "    \\midrule\n",
      "    Lex & \\texttt{lex\\_agg} & 63 & 49037 \\\\\n",
      "    Lex+dns+ip & \\texttt{lex\\_+dns\\_+ip\\_agg} & 111 & 49037 \\\\\n",
      "    Lex+...+geo & \\texttt{lex\\_+dns\\_+ip\\_+geo\\_agg} & 129 & 49037 \\\\\n",
      "    Lex+...+tls & \\texttt{lex\\_+dns\\_+ip\\_+tls\\_+geo\\_agg} & 153 & 49037 \\\\\n",
      "    Lex+...+rdap & \\texttt{lex\\_+dns\\_+ip\\_+tls\\_+geo\\_+rdap\\_agg} & 177 & 49037 \\\\\n",
      "    Lex+...+html & \\texttt{lex\\_+dns\\_+ip\\_+tls\\_+geo\\_+rdap\\_+html\\_agg} & 264 & 49037 \\\\\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# ┌────────────────────────────────────────────────────────────────────────────┐\n",
    "# │  Compact F1‐heatmap with model & subset abbreviations + LaTeX lookup      │\n",
    "# └────────────────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "print(results_grids.keys())\n",
    "\n",
    "# 1) LaTeX/PGF backend + styling\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"pgf\")\n",
    "mpl.rcParams.update({\n",
    "    \"pgf.texsystem\":  \"pdflatex\",\n",
    "    \"font.family\":    \"serif\",\n",
    "    \"text.usetex\":    True,\n",
    "    \"pgf.rcfonts\":    False,\n",
    "    \"font.size\":      16,\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"xtick.labelsize\":15,\n",
    "    \"ytick.labelsize\":15,\n",
    "    \"figure.figsize\": (8, 6),\n",
    "    \"figure.dpi\":     400,\n",
    "    \"axes.spines.top\":   False,\n",
    "    \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# 2) model full‐name → abbreviation\n",
    "model_abbrev = {\n",
    "    \"Random Forest\":  \"RF\",\n",
    "    \"Extreme Gradient Boosting\":      \"XGBoost\",\n",
    "    \"Decision Tree\":  \"DT\",\n",
    "    \"Ridge Classifier\":\"Ridge\",\n",
    "    \"KNeighbors\":    \"KNN\",\n",
    "    \"SVC\":           \"SVM\",\n",
    "    \"LogisticRegression\":\"LR\",\n",
    "    \"QuadraticDiscriminantAnalysis\":\"QDA\",\n",
    "    \"Extra Trees Classifier\":    \"ET\",\n",
    "    \"Light Gradient Boosting Machine\":    \"LGBM\",\n",
    "    \"K Neighbors Classifier\":    \"KNN\",\n",
    "    \"Gradient Boosting Classifier\":    \"GBM\",\n",
    "}\n",
    "\n",
    "# 3) subset key → descriptive label\n",
    "agg_abbrev = {\n",
    "    'lex__agg':                               'Lex',\n",
    "    'lex_+dns_+ip__agg':                      'Lex+dns+ip',\n",
    "    'lex_+dns_+ip_+geo__agg':                 'Lex+...+geo',\n",
    "    'lex_+dns_+ip_+tls_+geo__agg':            'Lex+...+tls',\n",
    "    'lex_+dns_+ip_+tls_+geo_+rdap__agg':       'Lex+...+rdap',\n",
    "    'lex_+dns_+ip_+tls_+geo_+rdap_+html__agg': 'Lex+...+html',\n",
    "}\n",
    "\n",
    "subset_abbrev = {\n",
    "    # new basic ones\n",
    "    'dns_':   'DNS',\n",
    "    'tls_':   'TLS',\n",
    "    'html_':  'HTML',\n",
    "    'geo_':   'Geo',\n",
    "    'rdap_':  'RDAP',\n",
    "    'lex_':   'Lex',\n",
    "    'ip_':    'IP',\n",
    "}\n",
    "\n",
    "subset_abbrev = agg_abbrev\n",
    "\n",
    "order_labels = list(reversed(list(subset_abbrev.values())))\n",
    "\n",
    "\n",
    "# 4) collect rows\n",
    "rows = []\n",
    "for key, grid in results_grids.items():\n",
    "    label = subset_abbrev[key]\n",
    "    top3 = grid.nlargest(3, \"F1\")[[\"Model\",\"F1\"]]\n",
    "    for rank, (_, row) in enumerate(top3.iterrows(), start=1):\n",
    "        raw = row[\"Model\"]\n",
    "        # pick abbreviation by substring match\n",
    "        abbrev = next((ab for k,ab in model_abbrev.items() if k in raw), raw)\n",
    "        rows.append({\"Subset\":label, \"Rank\":rank, \"Model\":abbrev, \"F1\":row[\"F1\"]})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "pivot_f1    = df.pivot(index=\"Subset\", columns=\"Rank\", values=\"F1\").reindex(order_labels)\n",
    "pivot_model = df.pivot(index=\"Subset\", columns=\"Rank\", values=\"Model\").reindex(order_labels)\n",
    "\n",
    "# 5) plot heatmap\n",
    "fig, ax = plt.subplots()\n",
    "vmin,vmax = pivot_f1.values.min(), pivot_f1.values.max()\n",
    "cax = ax.imshow(pivot_f1.values, aspect=\"auto\", cmap=\"viridis\", vmin=vmin, vmax=vmax)\n",
    "\n",
    "for (i,j), val in np.ndenumerate(pivot_f1.values):\n",
    "    txt = f\"{pivot_model.iloc[i,j]}\\n{val:.3f}\"\n",
    "    col = \"white\" if val < (vmin+vmax)/2 else \"black\"\n",
    "    ax.text(j,i, txt, ha=\"center\",va=\"center\", fontsize=16, color=col)\n",
    "\n",
    "ax.set_xticks([0,1,2]); ax.set_xticklabels([\"1st\",\"2nd\",\"3rd\"])\n",
    "ax.set_yticks(range(len(order_labels))); ax.set_yticklabels(order_labels)\n",
    "cb = fig.colorbar(cax, ax=ax, fraction=0.04, pad=0.04)\n",
    "cb.set_label(\"F1\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# 6) save\n",
    "fig.savefig(\"fig_f1_abbrev.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "lookup = [\n",
    "    (\"Lex\",          \"lex\\\\_agg\",                                 63, 49037),\n",
    "    (\"Lex+dns+ip\",   \"lex\\\\_+dns\\\\_+ip\\\\_agg\",                   111, 49037),\n",
    "    (\"Lex+...+geo\",  \"lex\\\\_+dns\\\\_+ip\\\\_+geo\\\\_agg\",            129, 49037),\n",
    "    (\"Lex+...+tls\",  \"lex\\\\_+dns\\\\_+ip\\\\_+tls\\\\_+geo\\\\_agg\",     153, 49037),\n",
    "    (\"Lex+...+rdap\", \"lex\\\\_+dns\\\\_+ip\\\\_+tls\\\\_+geo\\\\_+rdap\\\\_agg\", 177, 49037),\n",
    "    (\"Lex+...+html\", \"lex\\\\_+dns\\\\_+ip\\\\_+tls\\\\_+geo\\\\_+rdap\\\\_+html\\\\_agg\", 264, 49037),\n",
    "]\n",
    "\n",
    "table = [\n",
    "r\"\\begin{table}[ht]\",\n",
    "r\"  \\centering\",\n",
    "r\"  \\caption{Feature‐subset label lookup}\",\n",
    "r\"  \\begin{tabular}{llrr}\",\n",
    "r\"    \\toprule\",\n",
    "r\"    Label & Key & \\# features & \\# samples \\\\\",\n",
    "r\"    \\midrule\",\n",
    "]\n",
    "for lab,key,nf,ns in lookup:\n",
    "    table.append(f\"    {lab} & \\\\texttt{{{key}}} & {nf} & {ns} \\\\\\\\\")\n",
    "table += [\n",
    "r\"    \\bottomrule\",\n",
    "r\"  \\end{tabular}\",\n",
    "r\"\\end{table}\"\n",
    "]\n",
    "print(\"\\n\".join(table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855da8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
