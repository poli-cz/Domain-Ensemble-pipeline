{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 23:17:39.127194: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-02 23:17:39.127230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-02 23:17:39.128308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-02 23:17:39.134383: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-02 23:17:39.841606: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 23:17:40.561469: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-02 23:17:40.598266: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-02 23:17:40.601108: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-02 23:17:41.649060: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-02 23:17:41.650522: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-02 23:17:41.651756: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-02 23:17:41.652945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 1105 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Manually specify the path to the src folder\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.loader import Loader\n",
    "\n",
    "benign_dataset_filenames = [\n",
    "    '../parkets/benign/benign_2312_anonymized_HTML.parquet', \n",
    "    '../parkets/benign/umbrella_benign_FINISHED_HTML.parquet'\n",
    "        \n",
    "]\n",
    "malicious_dataset_filenames = [\n",
    "    '../parkets/malware_2406_strict_HTML.parquet'\n",
    "]\n",
    "\n",
    "# CONFIGURATION\n",
    "\n",
    "benign_label = \"benign\"\n",
    "malicious_label = \"malware\"\n",
    "\n",
    "class_map = {benign_label: 0, malicious_label: 1}\n",
    "# print labels from malicious datasets\n",
    "\n",
    "loader = Loader(benign_dataset_filenames, malicious_dataset_filenames, benign_label=benign_label, malicious_label=malicious_label, subsample=0.08)\n",
    "df = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poli/Desktop/git/deep_domain_detection/src/core/loader.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/loader.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/loader.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/loader.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/loader.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/loader.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n",
      "/home/poli/Desktop/git/deep_domain_detection/src/core/loader.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"label\"] = self.df[\"label\"].copy()\n"
     ]
    }
   ],
   "source": [
    "from core.loader import Segmenter\n",
    "\n",
    "# Define the aggregates that needs to be created\n",
    "\n",
    "aggregates = [\n",
    "    [\"lex_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"geo_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"tls_\", \"geo_\", \"rdap_\"],\n",
    "]\n",
    "\n",
    "segmenter = Segmenter(df)\n",
    "segmenter.create_base_subsets() # create base subsets\n",
    "segmenter.create_aggregated_subsets(aggregates)\n",
    "subset_dfs = segmenter.get_aggregated_subsets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm on subset:  lex_agg\n",
      "[LibSVM]............................................*....................*\n",
      "optimization finished, #iter = 64289\n",
      "obj = -31771.082690, rho = -0.399189\n",
      "nSV = 11546, nBSV = 379\n",
      "Total nSV = 11546\n",
      "Model parameters:\n",
      "C: 59\n",
      "break_ties: False\n",
      "cache_size: 200\n",
      "class_weight: balanced\n",
      "coef0: 0.0\n",
      "decision_function_shape: ovr\n",
      "degree: 3\n",
      "gamma: 0.1\n",
      "kernel: rbf\n",
      "max_iter: -1\n",
      "probability: False\n",
      "random_state: 42\n",
      "shrinking: True\n",
      "tol: 0.001\n",
      "verbose: True\n",
      "Classification report on test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.94      0.96      0.95      6538\n",
      "    phishing       0.79      0.68      0.73      1308\n",
      "\n",
      "    accuracy                           0.92      7846\n",
      "   macro avg       0.86      0.82      0.84      7846\n",
      "weighted avg       0.91      0.92      0.91      7846\n",
      "\n",
      "Classification report on train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      1.00      1.00     26151\n",
      "    phishing       0.99      1.00      0.99      5233\n",
      "\n",
      "    accuracy                           1.00     31384\n",
      "   macro avg       0.99      1.00      1.00     31384\n",
      "weighted avg       1.00      1.00      1.00     31384\n",
      "\n",
      "Saving as stage: stage_1\n",
      "Training svm on subset:  lex_+dns_+ip_+geo_agg\n",
      "[LibSVM]..............................*...........*\n",
      "optimization finished, #iter = 41463\n",
      "obj = -4639.115990, rho = -0.705474\n",
      "nSV = 23027, nBSV = 0\n",
      "Total nSV = 23027\n",
      "Model parameters:\n",
      "C: 59\n",
      "break_ties: False\n",
      "cache_size: 200\n",
      "class_weight: balanced\n",
      "coef0: 0.0\n",
      "decision_function_shape: ovr\n",
      "degree: 3\n",
      "gamma: 0.1\n",
      "kernel: rbf\n",
      "max_iter: -1\n",
      "probability: False\n",
      "random_state: 42\n",
      "shrinking: True\n",
      "tol: 0.001\n",
      "verbose: True\n",
      "Classification report on test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.93      0.99      0.96      6538\n",
      "    phishing       0.96      0.62      0.76      1308\n",
      "\n",
      "    accuracy                           0.93      7846\n",
      "   macro avg       0.94      0.81      0.86      7846\n",
      "weighted avg       0.93      0.93      0.93      7846\n",
      "\n",
      "Classification report on train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      1.00      1.00     26151\n",
      "    phishing       1.00      1.00      1.00      5233\n",
      "\n",
      "    accuracy                           1.00     31384\n",
      "   macro avg       1.00      1.00      1.00     31384\n",
      "weighted avg       1.00      1.00      1.00     31384\n",
      "\n",
      "Saving as stage: stage_2\n",
      "Training svm on subset:  lex_+dns_+ip_+tls_+geo_+rdap_agg\n",
      "[LibSVM].................................*.............*\n",
      "optimization finished, #iter = 46099\n",
      "obj = -4897.524604, rho = -0.742411\n",
      "nSV = 27704, nBSV = 0\n",
      "Total nSV = 27704\n",
      "Model parameters:\n",
      "C: 59\n",
      "break_ties: False\n",
      "cache_size: 200\n",
      "class_weight: balanced\n",
      "coef0: 0.0\n",
      "decision_function_shape: ovr\n",
      "degree: 3\n",
      "gamma: 0.1\n",
      "kernel: rbf\n",
      "max_iter: -1\n",
      "probability: False\n",
      "random_state: 42\n",
      "shrinking: True\n",
      "tol: 0.001\n",
      "verbose: True\n",
      "Classification report on test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.92      1.00      0.96      6538\n",
      "    phishing       0.99      0.56      0.71      1308\n",
      "\n",
      "    accuracy                           0.93      7846\n",
      "   macro avg       0.95      0.78      0.84      7846\n",
      "weighted avg       0.93      0.93      0.92      7846\n",
      "\n",
      "Classification report on train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      1.00      1.00     26151\n",
      "    phishing       1.00      1.00      1.00      5233\n",
      "\n",
      "    accuracy                           1.00     31384\n",
      "   macro avg       1.00      1.00      1.00     31384\n",
      "weighted avg       1.00      1.00      1.00     31384\n",
      "\n",
      "Saving as stage: stage_3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.model_wrapper import ModelWrapper\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "ARCH_NAME = \"svm\"\n",
    "VERSION = \"v1.1\"\n",
    "LR = 0.0023\n",
    "\n",
    "\n",
    "\n",
    "# Initialize ModelWrapper \n",
    "wrapper = ModelWrapper()\n",
    "\n",
    "def svm_convert(df):\n",
    "    df = df.fillna(0)\n",
    "    df = df.replace({True: 1, False: 0})\n",
    "    return np.array(df)\n",
    "\n",
    "i=1\n",
    "for prefix, subset_df in subset_dfs.items():\n",
    "    \n",
    "    print(f\"\\n🚀 Training SVM on '{prefix}' features…\")\n",
    "    \n",
    "    labels = subset_df['label'].apply(lambda x: class_map[x]) # y vector\n",
    "    features = subset_df.drop('label', axis=1).copy() # X matrix\n",
    "    \n",
    "    labels = svm_convert(labels)\n",
    "    features = loader.scale(features, stage=i, model=ARCH_NAME)\n",
    "    features = svm_convert(features)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        features,\n",
    "        labels,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        shuffle=True, \n",
    "        stratify=labels\n",
    "    )\n",
    "\n",
    "    # Following parameters were found by gradient grid search\n",
    "    params = {\n",
    "        \"C\": 59,\n",
    "        \"gamma\": 0.1,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"random_state\": 42,\n",
    "        \"class_weight\": \"balanced\"\n",
    "    }\n",
    "    \n",
    "    model = SVC(**params, verbose=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    ### stage evaluation ###\n",
    "    try:\n",
    "        # print the model's parameters\n",
    "        print(\"Model parameters:\")\n",
    "        for param, value in model.get_params().items():\n",
    "            print(f\"{param}: {value}\")\n",
    "            \n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred_train = model.predict(x_train)\n",
    "    \n",
    "        print(\"Classification report on test set:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=class_map.keys()))\n",
    "        print(\"Classification report on train set:\")\n",
    "        print(classification_report(y_train, y_pred_train, target_names=class_map.keys()))\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model evaluation: {e}\")\n",
    "\n",
    "\n",
    "    wrapper.save(model, arch_name=ARCH_NAME, label=malicious_label, prefix=f\"{prefix}\", version=VERSION)\n",
    "    i+=1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
