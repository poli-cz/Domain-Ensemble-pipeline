{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b715b0f7",
   "metadata": {},
   "source": [
    "# Load packages and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Manually specify the path to the src folder\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1258a0e",
   "metadata": {},
   "source": [
    "# Load datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069058d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.loader import Loader\n",
    "\n",
    "benign_dataset_filenames = [\n",
    "    '../parkets/benign/benign_2312_anonymized_HTML.parquet', \n",
    "    '../parkets/benign/umbrella_benign_FINISHED_HTML.parquet'\n",
    "        \n",
    "]\n",
    "malicious_dataset_filenames = [\n",
    "    '../parkets/malware_2406_strict_HTML.parquet'\n",
    "]\n",
    "\n",
    "# CONFIGURATION\n",
    "\n",
    "benign_label = \"benign\"\n",
    "malicious_label = \"phishing\"\n",
    "\n",
    "class_map = {benign_label: 0, malicious_label: 1}\n",
    "\n",
    "loader = Loader(benign_dataset_filenames, malicious_dataset_filenames, benign_label=benign_label, malicious_label=malicious_label, subsample=1.0)\n",
    "df = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca51639",
   "metadata": {},
   "source": [
    "# Split data into stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b37550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.loader import Segmenter\n",
    "\n",
    "# Define the aggregates that needs to be created\n",
    "\n",
    "aggregates = [\n",
    "    [\"lex_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"geo_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"tls_\", \"geo_\", \"rdap_\"],\n",
    "]\n",
    "\n",
    "segmenter = Segmenter(df)\n",
    "segmenter.create_base_subsets() # create base subsets\n",
    "segmenter.create_aggregated_subsets(aggregates)\n",
    "subset_dfs = segmenter.get_aggregated_subsets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fecd4d4",
   "metadata": {},
   "source": [
    "# Define the FFNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ecaeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation\n",
    "\n",
    "ARCH_NAME = \"feedforward\"\n",
    "VERSION = \"v1.0\"\n",
    "LR = 0.0023\n",
    "\n",
    "def build_feedforward_net(feature_size):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(feature_size,))\n",
    "    \n",
    "    # First hidden layer\n",
    "    \n",
    "    x = Dense(1024, activation=None)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Second hidden layer\n",
    "    x = Dense(512, activation=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Third hidden layer\n",
    "    x = Dense(256, activation=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Fourth hidden layer\n",
    "    x = Dense(128, activation=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Build and return the model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"ARCH_NAME\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c248ef",
   "metadata": {},
   "source": [
    "# For each subset/stage train one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a587cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.model_wrapper import ModelWrapper\n",
    "\n",
    "\n",
    "### Initialize GPU ###\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "# Initialize ModelWrapper and model histories\n",
    "wrapper = ModelWrapper()\n",
    "model_histories = []\n",
    "\n",
    "\n",
    "i=1\n",
    "for prefix, subset_df in subset_dfs.items():\n",
    "\n",
    "    print(f\"\\nðŸš€ Training Feedforward NN on '{prefix}' featuresâ€¦\")\n",
    "    labels   = subset_df['label'].map(class_map)\n",
    "    features = loader.scale(subset_df.drop('label', axis=1), stage=i, model=ARCH_NAME)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        features, labels,\n",
    "        test_size=0.2, random_state=42,\n",
    "        shuffle=True, stratify=labels\n",
    "    )\n",
    "\n",
    "    model = build_feedforward_net(X_train.shape[1])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LR),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['Precision', 'Recall', 'AUC']\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        batch_size=512,\n",
    "        epochs=15,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        class_weight={0: 1.0, 1: 0.8},\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "\n",
    "    model_histories.append({\"model_name\": prefix,\n",
    "                      \"history\": history})\n",
    "    \n",
    "\n",
    "    # Save the model using ModelWrapper\n",
    "    wrapper.save(model,\n",
    "                 arch_name=ARCH_NAME,\n",
    "                 label=malicious_label,\n",
    "                 prefix=prefix,\n",
    "                 version=VERSION)\n",
    "\n",
    "    # After training cleanup \n",
    "    K.clear_session()    \n",
    "    del model, history, X_train, X_test, Y_train, Y_test, X, features, labels\n",
    "    gc.collect()   \n",
    "    i += 1     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8da7a3",
   "metadata": {},
   "source": [
    "# Plot metrics for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6111038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume model_histories is a list of dicts, each with keys \"model_name\" and \"history\"\n",
    "def get_metric(history, metric_name):\n",
    "    if metric_name in history:\n",
    "        return history[metric_name]\n",
    "    for suffix in [\"_12\", \"_2\"]:\n",
    "        if f\"{metric_name}{suffix}\" in history:\n",
    "            return history[f\"{metric_name}{suffix}\"]\n",
    "    raise KeyError(f\"Metric {metric_name} not found in history.\")\n",
    "\n",
    "for model_entry in model_histories:\n",
    "    name = model_entry[\"model_name\"]\n",
    "    history = model_entry[\"history\"].history  # Keras history object\n",
    "\n",
    "    epoch_losses = get_metric(history, 'loss')\n",
    "    epoch_val_losses = get_metric(history, 'val_loss')\n",
    "    epoch_accuracies = get_metric(history, 'auc')\n",
    "    epoch_val_accuracies = get_metric(history, 'val_auc')\n",
    "    epoch_precisions = get_metric(history, 'precision')\n",
    "    epoch_val_precisions = get_metric(history, 'val_precision')\n",
    "    epoch_recalls = get_metric(history, 'recall')\n",
    "    epoch_val_recalls = get_metric(history, 'val_recall')\n",
    "\n",
    "    # Calculate F1 scores\n",
    "    def safe_f1(p, r):\n",
    "        return 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "\n",
    "    epoch_f1s = [safe_f1(p, r) for p, r in zip(epoch_precisions, epoch_recalls)]\n",
    "    epoch_val_f1s = [safe_f1(p, r) for p, r in zip(epoch_val_precisions, epoch_val_recalls)]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(epoch_losses, 'b--o', label='Training Loss')\n",
    "    plt.plot(epoch_val_losses, 'r--o', label='Validation Loss')\n",
    "    plt.title('Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.plot(epoch_accuracies, '--o', label='Training AUC', color='#ff7f0e')\n",
    "    plt.plot(epoch_val_accuracies, 'r--o', label='Validation AUC')\n",
    "    plt.title('AUC'); plt.xlabel('Epoch'); plt.ylabel('AUC'); plt.legend(); plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(epoch_precisions, 'g--o', label='Training Precision')\n",
    "    plt.plot(epoch_val_precisions, 'r--o', label='Validation Precision')\n",
    "    plt.title('Precision'); plt.xlabel('Epoch'); plt.ylabel('Precision'); plt.legend(); plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.plot(epoch_recalls, 'c--o', label='Training Recall')\n",
    "    plt.plot(epoch_val_recalls, 'r--o', label='Validation Recall')\n",
    "    plt.title('Recall'); plt.xlabel('Epoch'); plt.ylabel('Recall'); plt.legend(); plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.plot(epoch_f1s, 'm--o', label='Training F1')\n",
    "    plt.plot(epoch_val_f1s, 'r--o', label='Validation F1')\n",
    "    plt.title('F1 Score'); plt.xlabel('Epoch'); plt.ylabel('F1'); plt.legend(); plt.grid(True)\n",
    "\n",
    "    plt.suptitle(f\"Training Progress - {name}\", fontsize=16, y=1.02)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(f'./figures/training_{ARCH_NAME}_{name}_{VERSION}.png', dpi=500, bbox_inches='tight', pad_inches=0.5)\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
