{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b715b0f7",
   "metadata": {},
   "source": [
    "# Load Tensorflow and check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a3b996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 11:23:17.733676: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "/home/poli/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2025-05-14 11:23:17.733705: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: poli\n",
      "2025-05-14 11:23:17.733711: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: poli\n",
      "2025-05-14 11:23:17.733831: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 570.133.7\n",
      "2025-05-14 11:23:17.733850: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  570.86.10  Release Build  (dvs-builder@U16-I3-B16-4-3)  Thu Jan 16 03:40:42 UTC 2025\n",
      "GCC version:  gcc version 12.3.0 (Ubuntu 12.3.0-1ubuntu1~22.04) \n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# set relative path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Manually specify the path to the src folder\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.core.dtypes import common as com\n",
    "from core.loader import Loader\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "for device in device_lib.list_local_devices():\n",
    "    print(device.physical_device_desc)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1258a0e",
   "metadata": {},
   "source": [
    "# Load input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17229825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #############################################################\n",
    "# EDIT this to specify benign / malicious datasets to use     #\n",
    "# #############################################################\n",
    "benign_dataset_filenames = [\n",
    "    '../src/parkets/benign/benign_2312_anonymized_HTML.parquet', \n",
    "    '../src/parkets/benign/umbrella_benign_FINISHED_HTML.parquet'\n",
    "        \n",
    "]\n",
    "malicious_dataset_filenames = [\n",
    "    '../src/parkets/phishing_2406_strict_HTML.parquet'\n",
    "]\n",
    "\n",
    "# lex-dga-830k-pick.parquet LABEL je jmeno rodiny\n",
    "#  'parkets/malware_2406_strict_HTML.parquet'\n",
    "\n",
    "\n",
    "# #############################################################\n",
    "# EDIT this for to set appropriate labels (malware, dga, ...) #\n",
    "# #############################################################\n",
    "benign_label = \"benign\"\n",
    "malicious_label = \"phishing\"\n",
    "# #############################################################\n",
    "\n",
    "class_map = {benign_label: 0, malicious_label: 1}\n",
    "# print labels from malicious datasets\n",
    "\n",
    "loader = Loader(benign_dataset_filenames, malicious_dataset_filenames, benign_label=benign_label, malicious_label=malicious_label, subsample=0.05)\n",
    "df = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee8986",
   "metadata": {},
   "source": [
    "### Generate subsets of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52771c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 'dns_' contains 41 features and 49037 samples.\n",
      "Index(['label', 'dns_has_dnskey', 'dns_A_count', 'dns_AAAA_count',\n",
      "       'dns_MX_count', 'dns_NS_count', 'dns_TXT_count', 'dns_SOA_count',\n",
      "       'dns_CNAME_count', 'dns_zone_level', 'dns_zone_digit_count',\n",
      "       'dns_zone_len', 'dns_zone_entropy', 'dns_resolved_record_types',\n",
      "       'dns_dnssec_score', 'dns_ttl_avg', 'dns_ttl_stdev', 'dns_ttl_low',\n",
      "       'dns_ttl_mid', 'dns_ttl_distinct_count', 'dns_soa_primary_ns_level',\n",
      "       'dns_soa_primary_ns_digit_count', 'dns_soa_primary_ns_len',\n",
      "       'dns_soa_primary_ns_entropy', 'dns_soa_email_level',\n",
      "       'dns_soa_email_digit_count', 'dns_soa_email_len',\n",
      "       'dns_soa_email_entropy', 'dns_soa_refresh', 'dns_soa_retry',\n",
      "       'dns_soa_expire', 'dns_soa_min_ttl', 'dns_domain_name_in_mx',\n",
      "       'dns_mx_avg_len', 'dns_mx_avg_entropy', 'dns_txt_avg_len',\n",
      "       'dns_txt_avg_entropy', 'dns_txt_external_verification_score',\n",
      "       'dns_txt_spf_exists', 'dns_txt_dkim_exists', 'dns_txt_dmarc_exists'],\n",
      "      dtype='object')\n",
      "Subset 'tls_' contains 25 features and 49037 samples.\n",
      "Index(['label', 'tls_has_tls', 'tls_chain_len', 'tls_is_self_signed',\n",
      "       'tls_root_authority_hash', 'tls_leaf_authority_hash',\n",
      "       'tls_negotiated_version_id', 'tls_negotiated_cipher_id',\n",
      "       'tls_root_cert_validity_len', 'tls_leaf_cert_validity_len',\n",
      "       'tls_broken_chain', 'tls_expired_chain', 'tls_total_extension_count',\n",
      "       'tls_critical_extensions', 'tls_with_policies_crt_count',\n",
      "       'tls_percentage_crt_with_policies', 'tls_x509_anypolicy_crt_count',\n",
      "       'tls_iso_policy_crt_count', 'tls_joint_isoitu_policy_crt_count',\n",
      "       'tls_subject_count', 'tls_server_auth_crt_count',\n",
      "       'tls_client_auth_crt_count', 'tls_CA_certs_in_chain_ratio',\n",
      "       'tls_unique_SLD_count', 'tls_common_name_count'],\n",
      "      dtype='object')\n",
      "Subset 'html_' contains 88 features and 49037 samples.\n",
      "Index(['label', 'html_num_of_tags', 'html_num_of_paragraphs',\n",
      "       'html_num_of_divs', 'html_num_of_titles', 'html_num_of_external_js',\n",
      "       'html_num_of_links', 'html_num_of_scripts', 'html_num_of_scripts_async',\n",
      "       'html_num_of_scripts_type', 'html_num_of_anchors',\n",
      "       'html_num_of_anchors_to_hash', 'html_num_of_anchors_to_https',\n",
      "       'html_num_of_anchors_to_com', 'html_num_of_inputs',\n",
      "       'html_num_of_input_password', 'html_num_of_hidden_elements',\n",
      "       'html_num_of_input_hidden', 'html_num_of_objects', 'html_num_of_embeds',\n",
      "       'html_num_of_frame', 'html_num_of_iframe', 'html_num_of_iframe_src',\n",
      "       'html_num_of_iframe_src_https', 'html_num_of_center',\n",
      "       'html_num_of_imgs', 'html_num_of_imgs_src', 'html_num_of_meta',\n",
      "       'html_num_of_links_href', 'html_num_of_links_href_https',\n",
      "       'html_num_of_links_href_css', 'html_num_of_links_type',\n",
      "       'html_num_of_link_type_app', 'html_num_of_link_rel',\n",
      "       'html_num_of_all_hrefs', 'html_num_of_form_action',\n",
      "       'html_num_of_form_http', 'html_num_of_strong', 'html_no_hrefs',\n",
      "       'html_internal_href_ratio', 'html_num_of_internal_hrefs',\n",
      "       'html_external_href_ratio', 'html_num_of_external_href',\n",
      "       'html_num_of_icon', 'html_icon_external', 'html_num_of_form_php',\n",
      "       'html_num_of_form_hash', 'html_num_of_form_js', 'html_malicious_form',\n",
      "       'html_most_common', 'html_num_of_css_internal',\n",
      "       'html_num_of_css_external', 'html_num_of_anchors_to_content',\n",
      "       'html_num_of_anchors_to_void', 'html_num_of_words', 'html_num_of_lines',\n",
      "       'html_unique_words', 'html_average_word_len',\n",
      "       'html_blocked_keywords_label', 'html_num_of_blank_spaces',\n",
      "       'html_create_element', 'html_write', 'html_char_code_at', 'html_concat',\n",
      "       'html_escape', 'html_eval', 'html_exec', 'html_from_char_code',\n",
      "       'html_link', 'html_parse_int', 'html_replace', 'html_search',\n",
      "       'html_substring', 'html_unescape', 'html_add_event_listener',\n",
      "       'html_set_interval', 'html_set_timeout', 'html_push', 'html_index_of',\n",
      "       'html_document_write', 'html_get', 'html_find',\n",
      "       'html_document_create_element', 'html_window_set_timeout',\n",
      "       'html_window_set_interval', 'html_hex_encoding',\n",
      "       'html_unicode_encoding', 'html_long_variable_name'],\n",
      "      dtype='object')\n",
      "Subset 'geo_' contains 19 features and 49037 samples.\n",
      "Index(['label', 'geo_countries_count', 'geo_continents_count',\n",
      "       'geo_malic_host_country', 'geo_lat_stdev', 'geo_lon_stdev',\n",
      "       'geo_mean_lat', 'geo_mean_lon', 'geo_min_lat', 'geo_max_lat',\n",
      "       'geo_min_lon', 'geo_max_lon', 'geo_lat_range', 'geo_lon_range',\n",
      "       'geo_centroid_lat', 'geo_centroid_lon', 'geo_estimated_area',\n",
      "       'geo_continent_hash', 'geo_countries_hash'],\n",
      "      dtype='object')\n",
      "Subset 'rdap_' contains 25 features and 49037 samples.\n",
      "Index(['label', 'rdap_registration_period', 'rdap_domain_age',\n",
      "       'rdap_time_from_last_change', 'rdap_domain_active_time',\n",
      "       'rdap_has_dnssec', 'rdap_registrar_name_len',\n",
      "       'rdap_registrar_name_entropy', 'rdap_registrar_name_hash',\n",
      "       'rdap_registrant_name_len', 'rdap_registrant_name_entropy',\n",
      "       'rdap_admin_name_len', 'rdap_admin_name_entropy',\n",
      "       'rdap_admin_email_len', 'rdap_admin_email_entropy', 'rdap_ip_v4_count',\n",
      "       'rdap_ip_v6_count', 'rdap_ip_shortest_v4_prefix_len',\n",
      "       'rdap_ip_longest_v4_prefix_len', 'rdap_ip_shortest_v6_prefix_len',\n",
      "       'rdap_ip_longest_v6_prefix_len', 'rdap_ip_avg_admin_name_len',\n",
      "       'rdap_ip_avg_admin_name_entropy', 'rdap_ip_avg_admin_email_len',\n",
      "       'rdap_ip_avg_admin_email_entropy'],\n",
      "      dtype='object')\n",
      "Subset 'lex_' contains 63 features and 49037 samples.\n",
      "Index(['label', 'lex_name_len', 'lex_has_digit', 'lex_phishing_keyword_count',\n",
      "       'lex_benign_keyword_count', 'lex_consecutive_chars', 'lex_tld_len',\n",
      "       'lex_tld_abuse_score', 'lex_tld_hash', 'lex_sld_len',\n",
      "       'lex_sld_norm_entropy', 'lex_sld_digit_count', 'lex_sld_digit_ratio',\n",
      "       'lex_sld_phishing_keyword_count', 'lex_sld_vowel_count',\n",
      "       'lex_sld_vowel_ratio', 'lex_sld_consonant_count',\n",
      "       'lex_sld_consonant_ratio', 'lex_sld_non_alphanum_count',\n",
      "       'lex_sld_non_alphanum_ratio', 'lex_sld_hex_count', 'lex_sld_hex_ratio',\n",
      "       'lex_sub_count', 'lex_stld_unique_char_count', 'lex_begins_with_digit',\n",
      "       'lex_www_flag', 'lex_sub_max_consonant_len', 'lex_sub_norm_entropy',\n",
      "       'lex_sub_digit_count', 'lex_sub_digit_ratio', 'lex_sub_vowel_count',\n",
      "       'lex_sub_vowel_ratio', 'lex_sub_consonant_count',\n",
      "       'lex_sub_consonant_ratio', 'lex_sub_non_alphanum_count',\n",
      "       'lex_sub_non_alphanum_ratio', 'lex_sub_hex_count', 'lex_sub_hex_ratio',\n",
      "       'lex_phishing_bigram_matches', 'lex_phishing_trigram_matches',\n",
      "       'lex_phishing_tetragram_matches', 'lex_phishing_pentagram_matches',\n",
      "       'lex_malware_bigram_matches', 'lex_malware_trigram_matches',\n",
      "       'lex_malware_tetragram_matches', 'lex_dga_bigram_matches',\n",
      "       'lex_dga_trigram_matches', 'lex_dga_tetragram_matches',\n",
      "       'lex_avg_part_len', 'lex_stdev_part_lens', 'lex_longest_part_len',\n",
      "       'lex_short_part_count', 'lex_medium_part_count', 'lex_long_part_count',\n",
      "       'lex_superlong_part_count', 'lex_shortest_sub_len',\n",
      "       'lex_ipv4_in_domain', 'lex_has_trusted_suffix',\n",
      "       'lex_has_wellknown_suffix', 'lex_has_cdn_suffix', 'lex_has_vps_suffix',\n",
      "       'lex_has_img_suffix', 'lex_suffix_score'],\n",
      "      dtype='object')\n",
      "Subset 'ip_' contains 9 features and 49037 samples.\n",
      "Index(['label', 'ip_count', 'ip_mean_average_rtt', 'ip_v4_ratio',\n",
      "       'ip_a_aaaa_to_all_ratio', 'ip_entropy', 'ip_as_address_entropy',\n",
      "       'ip_asn_entropy', 'ip_distinct_as_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define prefixes\n",
    "prefixes = [\"dns_\", \"tls_\", \"html_\", \"geo_\", \"rdap_\", \"lex_\", \"ip_\"]\n",
    "\n",
    "# Dictionary to store filtered datasets\n",
    "subset_dfs = {}\n",
    "\n",
    "# Create subsets for each prefix\n",
    "for prefix in prefixes:\n",
    "    subset_df = df.loc[:, df.columns.str.startswith(prefix) | df.columns.isin(['label'])]\n",
    "    \n",
    "    # Store in dictionary\n",
    "    subset_dfs[prefix] = subset_df\n",
    "\n",
    "    print(f\"Subset '{prefix}' contains {subset_df.shape[1]} features and {subset_df.shape[0]} samples.\")\n",
    "    # print all columns in the subset\n",
    "    print(subset_df.columns)\n",
    "    \n",
    "    \n",
    "    \n",
    "## Agregations \n",
    "\n",
    "# agregate dns and rdap features and append to prefixes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c3b54",
   "metadata": {},
   "source": [
    "#### Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce72943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 'lex__agg' contains 63 features and 49037 samples.\n",
      "Subset 'lex_+dns_+ip__agg' contains 111 features and 49037 samples.\n",
      "Subset 'lex_+dns_+ip_+geo__agg' contains 129 features and 49037 samples.\n",
      "Subset 'lex_+dns_+ip_+tls_+geo__agg' contains 153 features and 49037 samples.\n",
      "Subset 'lex_+dns_+ip_+tls_+geo_+rdap__agg' contains 177 features and 49037 samples.\n",
      "Subset 'lex_+dns_+ip_+tls_+geo_+rdap_+html__agg' contains 264 features and 49037 samples.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "subset_dfs = {}\n",
    "# Define the list of aggregates\n",
    "aggregates = [\n",
    "    [\"lex_\"],                                                   # 1. step\n",
    "    [\"lex_\", \"dns_\", \"ip_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"geo_\"],                            # 2. step\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"tls_\", \"geo_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"tls_\", \"geo_\", \"rdap_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"tls_\", \"geo_\", \"rdap_\", \"html_\"]   # 3. step\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process each aggregation group\n",
    "for group in aggregates:\n",
    "    # Build a regex pattern to match any of the prefixes in the group\n",
    "    pattern = '|'.join(f'^{prefix}' for prefix in group)\n",
    "\n",
    "    # Select columns starting with any of the specified prefixes or the 'label' column\n",
    "    subset_df = df.loc[:, df.columns.str.contains(pattern) | (df.columns == 'label')]\n",
    "\n",
    "    # Ensure 'index' column is not included\n",
    "    subset_df = subset_df.loc[:, ~subset_df.columns.str.contains('^index$', case=False)]\n",
    "\n",
    "    # Reset index without adding it as a column\n",
    "    subset_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Create a unique key for the aggregated data\n",
    "    key = '+'.join(group) + \"_agg\"\n",
    "\n",
    "    # Store the aggregated DataFrame in the dictionary\n",
    "    subset_dfs[key] = subset_df\n",
    "\n",
    "# Iterate over subsets_df and print the number of benign and malicious samples\n",
    "for key, subset_df in subset_dfs.items():\n",
    "    print(f\"Subset '{key}' contains {subset_df.shape[1]} features and {subset_df.shape[0]} samples.\")\n",
    "    # Print all column names to verify index removal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb06f7b",
   "metadata": {},
   "source": [
    "### Pycarrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to store the top 3 models and results grids for each feature subset\n",
    "top3_models = {}\n",
    "results_grids = {}\n",
    "\n",
    "# Iterate through each subset and train models\n",
    "for prefix, subset_df in subset_dfs.items():\n",
    "    print(f\"\\nüîç Running model comparison for '{prefix}' features...\")\n",
    "\n",
    "    # PyCaret Setup\n",
    "    clf = setup(subset_df, target='label', session_id=54, log_experiment=False, experiment_name=f'exp_{prefix}', use_gpu=True, train_size=0.8, index=False)\n",
    "    \n",
    "    # Compare models and capture the top 3 models\n",
    "    top_models = compare_models(sort='F1', n_select=3)\n",
    "    \n",
    "    # Store the top 3 models\n",
    "    top3_models[prefix] = top_models\n",
    "    \n",
    "    # Pulling the last model score grid from PyCaret after model comparison\n",
    "    results_grid = pull()\n",
    "    results_grids[prefix] = results_grid\n",
    "    \n",
    "    # Print information about the top 3 models for the subset\n",
    "    print(f\"‚úÖ Top 3 models for '{prefix}' features:\")\n",
    "    for model in top_models:\n",
    "        print(model)\n",
    "\n",
    "# Compile all results into a single DataFrame for comparison\n",
    "all_results = pd.DataFrame()\n",
    "for prefix, grid in results_grids.items():\n",
    "    grid['Subset'] = prefix\n",
    "    all_results = pd.concat([all_results, grid], axis=0)\n",
    "\n",
    "# Reset index for a clean look\n",
    "all_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the consolidated results DataFrame\n",
    "print(\"üìä Consolidated Results across all feature subsets:\")\n",
    "display(all_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476fed9",
   "metadata": {},
   "source": [
    "### save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcfb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save grids as images to foldre grids, create the folder if it does not exist\n",
    "import os\n",
    "if not os.path.exists('grids'):\n",
    "    os.makedirs('grids')\n",
    "    \n",
    "for prefix, grid in results_grids.items():\n",
    "    grid.to_csv(f'grids/{malicious_label}{prefix}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ab84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 3 skupiny graf≈Ø \n",
    "\n",
    "# 1. Samotn√© subsety - DONE \n",
    "    # phish\n",
    "    # malware\n",
    "    \n",
    "# 2. Agregace (jen agregovan√© subsety)\n",
    "    # phish\n",
    "    # malware\n",
    "    \n",
    "# 3. Staged (3-4 f√°ze)\n",
    "    # phish\n",
    "\n",
    "BACKUP_FILE = './tmp/phishing_aggregated.pickle'\n",
    "\n",
    "def save_to_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {filename}.\")\n",
    "    \n",
    "    # save all the models \n",
    "    \n",
    "\n",
    "def load_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Data loaded from {filename}.\")\n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `results_grids` and `best_models` are the data you want to save.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ae7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save = {\n",
    "    'results_grids': results_grids,\n",
    "    'top3_models': top3_models,\n",
    "    'subset_dfs': subset_dfs\n",
    "}\n",
    "\n",
    "save_to_pickle(data_to_save, BACKUP_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = load_from_pickle(BACKUP_FILE)\n",
    "results_grids = loaded_data['results_grids']\n",
    "top3_models = loaded_data['top3_models']\n",
    "subset_dfs = loaded_data['subset_dfs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8d161",
   "metadata": {},
   "source": [
    "### Visualize top models and overall results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba51849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting best F1 Scores and top models\n",
    "best_f1_scores = []\n",
    "model_names = []\n",
    "subsets = []\n",
    "top_models = {}\n",
    "\n",
    "for prefix, grid in results_grids.items():\n",
    "    # Best F1 score\n",
    "    best_f1 = grid['F1'].max()\n",
    "    best_f1_scores.append(best_f1)\n",
    "    \n",
    "    # Top 3 models\n",
    "    top_3_models = grid.nlargest(3, 'F1')[['Model', 'F1']]\n",
    "    top_models[prefix] = top_3_models\n",
    "    model_names.append(top_3_models.iloc[0]['Model'])\n",
    "    subsets = [s.replace('_html', '') for s in subsets]\n",
    "    \n",
    "    subsets.append(prefix)\n",
    "    \n",
    "# remove html from subsets\n",
    "\n",
    "\n",
    "# Initialize figure\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# set header \n",
    "plt.suptitle('Srovn√°n√≠ klasifikace podle skupin p≈ô√≠znak≈Ø', fontsize=16)\n",
    "\n",
    "# Plot 1: Best F1 Scores by Feature Subset\n",
    "plt.subplot(1, 3, 1)\n",
    "bars = plt.barh(subsets, best_f1_scores, color='skyblue')\n",
    "plt.xlabel('F1')\n",
    "plt.title('Nejlep≈°√≠ F1 sk√≥re podle skupin p≈ô√≠znak≈Ø')\n",
    "plt.gca().invert_yaxis()\n",
    "# Annotate exact F1 scores\n",
    "for bar, score in zip(bars, best_f1_scores):\n",
    "    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{score:.4f}', va='center')\n",
    "\n",
    "# Plot 2: Top Three Models for each Feature Subset\n",
    "plt.subplot(1, 3, 2)\n",
    "for i, (prefix, top_3) in enumerate(top_models.items()):\n",
    "    for j, (index, row) in enumerate(top_3.iterrows()):\n",
    "        plt.barh(f'{prefix} {j+1}', row['F1'], color='lightgreen')\n",
    "        plt.text(row['F1'], i * 3 + j, f'{row[\"Model\"]} ({row[\"F1\"]:.4f})', va='center')\n",
    "plt.title('T≈ôi nejlep≈°√≠ modely pro ka≈ædou skupinu p≈ô√≠znak≈Ø')\n",
    "plt.xlabel('F1')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Plot 3: Ranking of Models Across All Feature Sets\n",
    "model_rankings = pd.concat([grid[['Model', 'F1']] for grid in results_grids.values()])\n",
    "mean_f1_by_model = model_rankings.groupby('Model')['F1'].mean().sort_values(ascending=True)\n",
    "plt.subplot(1, 3, 3)\n",
    "bars = plt.barh(mean_f1_by_model.index, mean_f1_by_model, color='salmon')\n",
    "plt.title('APr≈Ømƒõrn√© F1 sk√≥re podle model≈Ø')\n",
    "plt.xlabel('F1')\n",
    "# Annotate exact average F1 scores\n",
    "for bar, score in zip(bars, mean_f1_by_model):\n",
    "    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{score:.4f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print all items in top3_models\n",
    "#for key, value in top3_models.items():\n",
    "    #print(key, value)\n",
    "    \n",
    "#subset = 'rdap_'\n",
    "\n",
    "prefixes = [\"lex_\"]\n",
    "\n",
    "for prefix in prefixes:\n",
    "\n",
    "    # Initialize SHAP explainer\n",
    "    explainer = shap.TreeExplainer(top3_models[prefix][0])\n",
    "\n",
    "    # Compute SHAP values\n",
    "    X = subset_dfs[prefix].drop('label', axis=1)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # Summary plot (beeswarm)\n",
    "    print(\"Using prefix: \", prefix)\n",
    "    shap.summary_plot(shap_values, X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a784c35",
   "metadata": {},
   "source": [
    "# Combine models\n",
    "\n",
    "For each subset, create blended model from top3 classifiers of this subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12415246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "\n",
    "def tune_and_stack_all_models():\n",
    "    # Dictionary to store tuned models and their F1 scores for each subset\n",
    "    all_tuned_models = {}\n",
    "    all_f1_scores = {}\n",
    "\n",
    "    # Iterate over each subset in subset_dfs\n",
    "    for subset_name, subset_df in subset_dfs.items():\n",
    "        print(f\"\\nüîç Processing subset: {subset_name}\")\n",
    "\n",
    "        # PyCaret Setup\n",
    "        clf = setup(subset_df, target='label', session_id=897, log_experiment=False, experiment_name=f'ensemble_tune_{subset_name}', index=False, use_gpu=True)\n",
    "\n",
    "        # Retrieve top models stored for the subset\n",
    "        top_models = top3_models[subset_name]\n",
    "\n",
    "        # Stacking the top models\n",
    "        blended_model = stack_models(estimator_list=top_models)\n",
    "\n",
    "        # Tuning the blended model\n",
    "        tuned_model = tune_model(blended_model, optimize='F1', n_iter=10)\n",
    "\n",
    "        # Retrieve F1 score of the tuned model\n",
    "        f1_score = pull().iloc[-1]['F1']\n",
    "\n",
    "        # Saving the tuned model and F1 score\n",
    "        model_name = f'tuned_{subset_name}'\n",
    "        saved_model = save_model(tuned_model, model_name)\n",
    "        all_tuned_models[subset_name] = saved_model\n",
    "        all_f1_scores[subset_name] = f1_score\n",
    "\n",
    "        print(f\"‚úÖ Tuned and saved model for '{subset_name}' with F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "    # Save all_tuned_models and their F1 scores to pickle\n",
    "    save_to_pickle(all_tuned_models, 'all_tuned_models.pickle')\n",
    "    save_to_pickle(all_f1_scores, 'all_tuned_f1_scores.pickle')\n",
    "\n",
    "    print(\"\\nüîó Final stacked model across all subsets created and saved.\")\n",
    "    return all_tuned_models\n",
    "\n",
    "# Execute the function\n",
    "final_model = tune_and_stack_all_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159bd9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have best_f1_scores and subsets from previous results\n",
    "# Load the F1 scores of the tuned models\n",
    "all_f1_scores = load_from_pickle('all_tuned_f1_scores.pickle')\n",
    "\n",
    "# Data for plotting\n",
    "original_f1 = best_f1_scores\n",
    "tuned_f1 = [all_f1_scores[subset] for subset in subsets]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "x = range(len(subsets))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.barh(x, original_f1, width, label='Original Best F1', color='skyblue')\n",
    "rects2 = ax.barh([p + width for p in x], tuned_f1, width, label='Tuned Blended F1', color='lightgreen')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('F1 Score')\n",
    "ax.set_title('F1 Score Comparison by Subset')\n",
    "ax.set_yticks([p + width / 2 for p in x])\n",
    "ax.set_yticklabels(subsets)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8acfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all models into one ensemble model\n",
    "from pycaret.classification import *\n",
    "\n",
    "def combine_all_models():\n",
    "    # load models from pickle\n",
    "\n",
    "    \n",
    "    final_stacked_model = stack_models(estimator_list=list(load_from_pickle('all_tuned_models.pickle').values()))\n",
    "\n",
    "    # Saving the final stacked model\n",
    "    save_model(final_stacked_model, 'final_stacked_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb3be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33631970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43fe2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
