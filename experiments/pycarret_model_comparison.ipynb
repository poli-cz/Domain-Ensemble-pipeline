{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b715b0f7",
   "metadata": {},
   "source": [
    "# Load Tensorflow and check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Manually specify the path to the src folder\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1258a0e",
   "metadata": {},
   "source": [
    "# Load input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17229825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.loader import Loader\n",
    "\n",
    "benign_dataset_filenames = [\n",
    "    '../parkets/benign/benign_2312_anonymized_HTML.parquet', \n",
    "    '../parkets/benign/umbrella_benign_FINISHED_HTML.parquet'\n",
    "        \n",
    "]\n",
    "malicious_dataset_filenames = [\n",
    "    '../parkets/malware_2406_strict_HTML.parquet'\n",
    "]\n",
    "\n",
    "# CONFIGURATION\n",
    "\n",
    "benign_label = \"benign\"\n",
    "malicious_label = \"phishing\"\n",
    "\n",
    "class_map = {benign_label: 0, malicious_label: 1}\n",
    "\n",
    "loader = Loader(benign_dataset_filenames, malicious_dataset_filenames, benign_label=benign_label, malicious_label=malicious_label, subsample=1.0)\n",
    "df = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee8986",
   "metadata": {},
   "source": [
    "# Generate basic subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52771c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define prefixes\n",
    "prefixes = [\"dns_\", \"tls_\", \"html_\", \"geo_\", \"rdap_\", \"lex_\", \"ip_\"]\n",
    "\n",
    "# Dictionary to store filtered datasets\n",
    "subset_dfs = {}\n",
    "\n",
    "# Create subsets for each prefix\n",
    "for prefix in prefixes:\n",
    "    subset_df = df.loc[:, df.columns.str.startswith(prefix) | df.columns.isin(['label'])]\n",
    "    \n",
    "    # Store in dictionary\n",
    "    subset_dfs[prefix] = subset_df\n",
    "\n",
    "    print(f\"Subset '{prefix}' contains {subset_df.shape[1]} features and {subset_df.shape[0]} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c3b54",
   "metadata": {},
   "source": [
    "# From basic subsets, generate aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce72943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "subset_dfs = {}\n",
    "# Define the list of aggregates\n",
    "aggregates = [\n",
    "    [\"lex_\"],                                                   # 1. Stage\n",
    "    [\"lex_\", \"dns_\", \"ip_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"geo_\"],                            # 2. Stage\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"tls_\", \"geo_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"tls_\", \"geo_\", \"rdap_\"],\n",
    "    [\"lex_\", \"dns_\", \"ip_\", \"tls_\", \"geo_\", \"rdap_\", \"html_\"]   # 3. Stage\n",
    "]\n",
    "\n",
    "\n",
    "# Process each aggregation group\n",
    "for group in aggregates:\n",
    "    # Build a regex pattern to match any of the prefixes in the group\n",
    "    pattern = '|'.join(f'^{prefix}' for prefix in group)\n",
    "\n",
    "    # Select columns starting with any of the specified prefixes or the 'label' column\n",
    "    subset_df = df.loc[:, df.columns.str.contains(pattern) | (df.columns == 'label')]\n",
    "\n",
    "    # Ensure 'index' column is not included\n",
    "    subset_df = subset_df.loc[:, ~subset_df.columns.str.contains('^index$', case=False)]\n",
    "\n",
    "    # Reset index without adding it as a column\n",
    "    subset_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Create a unique key for the aggregated data\n",
    "    key = '+'.join(group) + \"_agg\"\n",
    "\n",
    "    # Store the aggregated DataFrame in the dictionary\n",
    "    subset_dfs[key] = subset_df\n",
    "\n",
    "# Iterate over subsets_df and print the number of benign and malicious samples\n",
    "for key, subset_df in subset_dfs.items():\n",
    "    print(f\"Subset '{key}' contains {subset_df.shape[1]} features and {subset_df.shape[0]} samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb06f7b",
   "metadata": {},
   "source": [
    "# Pycarret\n",
    "Run pycaret comparison, for all subsets and aggergations try classification with all 12 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to store the top 3 models and results grids for each feature subset\n",
    "top3_models = {}\n",
    "results_grids = {}\n",
    "\n",
    "# Iterate through each subset and train models\n",
    "for prefix, subset_df in subset_dfs.items():\n",
    "    print(f\"\\nüîç Running model comparison for '{prefix}' features...\")\n",
    "\n",
    "    # PyCaret Setup\n",
    "    clf = setup(subset_df, target='label', session_id=54, log_experiment=False, experiment_name=f'exp_{prefix}', use_gpu=True, train_size=0.8, index=False)\n",
    "    \n",
    "    # Compare models and capture the top 3 models\n",
    "    top_models = compare_models(sort='F1', n_select=3)\n",
    "    \n",
    "    # Store the top 3 models\n",
    "    top3_models[prefix] = top_models\n",
    "    \n",
    "    # Pulling the last model score grid from PyCaret after model comparison\n",
    "    results_grid = pull()\n",
    "    results_grids[prefix] = results_grid\n",
    "    \n",
    "    # Print information about the top 3 models for the subset\n",
    "    print(f\"‚úÖ Top 3 models for '{prefix}' features:\")\n",
    "    for model in top_models:\n",
    "        print(model)\n",
    "\n",
    "# Compile all results into a single DataFrame for comparison\n",
    "all_results = pd.DataFrame()\n",
    "for prefix, grid in results_grids.items():\n",
    "    grid['Subset'] = prefix\n",
    "    all_results = pd.concat([all_results, grid], axis=0)\n",
    "\n",
    "# Reset index for a clean look\n",
    "all_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the consolidated results DataFrame\n",
    "print(\"üìä Consolidated Results across all feature subsets:\")\n",
    "display(all_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476fed9",
   "metadata": {},
   "source": [
    "# Results are saved to grid folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcfb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "if not os.path.exists('grids'):\n",
    "    os.makedirs('grids')\n",
    "    \n",
    "for prefix, grid in results_grids.items():\n",
    "    grid.to_csv(f'grids/{malicious_label}{prefix}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d8ff7",
   "metadata": {},
   "source": [
    "## Save / Load results\n",
    "This code can be used to simply load results from previous runs, since it can take a long time. You can specificy folder to use as cachem normaly tmp folder is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ab84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "BACKUP_FILE = '../src/tmp/phishing_agregate_to_good.pickle'\n",
    "\n",
    "def save_to_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {filename}.\")\n",
    "    \n",
    "    # save all the models \n",
    "    \n",
    "\n",
    "def load_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Data loaded from {filename}.\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ae7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save = {\n",
    "    'results_grids': results_grids,\n",
    "    'top3_models': top3_models,\n",
    "    'subset_dfs': subset_dfs\n",
    "}\n",
    "\n",
    "save_to_pickle(data_to_save, BACKUP_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = load_from_pickle(BACKUP_FILE)\n",
    "results_grids = loaded_data['results_grids']\n",
    "top3_models = loaded_data['top3_models']\n",
    "subset_dfs = loaded_data['subset_dfs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8d161",
   "metadata": {},
   "source": [
    "### Visualize top models and overall results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba51849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Extracting best F1 Scores and top models\n",
    "best_f1_scores = []\n",
    "model_names = []\n",
    "subsets = []\n",
    "top_models = {}\n",
    "\n",
    "for prefix, grid in results_grids.items():\n",
    "    # Best F1 score\n",
    "    best_f1 = grid['F1'].max()\n",
    "    best_f1_scores.append(best_f1)\n",
    "    \n",
    "    # Top 3 models\n",
    "    top_3_models = grid.nlargest(3, 'F1')[['Model', 'F1']]\n",
    "    top_models[prefix] = top_3_models\n",
    "    model_names.append(top_3_models.iloc[0]['Model'])\n",
    "    subsets = [s.replace('_html', '') for s in subsets]\n",
    "    \n",
    "    subsets.append(prefix)\n",
    "    \n",
    "# remove html from subsets\n",
    "\n",
    "\n",
    "# Initialize figure\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# set header \n",
    "plt.suptitle('Srovn√°n√≠ klasifikace podle skupin p≈ô√≠znak≈Ø', fontsize=16)\n",
    "\n",
    "# Plot 1: Best F1 Scores by Feature Subset\n",
    "plt.subplot(1, 3, 1)\n",
    "bars = plt.barh(subsets, best_f1_scores, color='skyblue')\n",
    "plt.xlabel('F1')\n",
    "plt.title('Nejlep≈°√≠ F1 sk√≥re podle skupin p≈ô√≠znak≈Ø')\n",
    "plt.gca().invert_yaxis()\n",
    "# Annotate exact F1 scores\n",
    "for bar, score in zip(bars, best_f1_scores):\n",
    "    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{score:.4f}', va='center')\n",
    "\n",
    "# Plot 2: Top Three Models for each Feature Subset\n",
    "plt.subplot(1, 3, 2)\n",
    "for i, (prefix, top_3) in enumerate(top_models.items()):\n",
    "    for j, (index, row) in enumerate(top_3.iterrows()):\n",
    "        plt.barh(f'{prefix} {j+1}', row['F1'], color='lightgreen')\n",
    "        plt.text(row['F1'], i * 3 + j, f'{row[\"Model\"]} ({row[\"F1\"]:.4f})', va='center')\n",
    "plt.title('T≈ôi nejlep≈°√≠ modely pro ka≈ædou skupinu p≈ô√≠znak≈Ø')\n",
    "plt.xlabel('F1')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Plot 3: Ranking of Models Across All Feature Sets\n",
    "model_rankings = pd.concat([grid[['Model', 'F1']] for grid in results_grids.values()])\n",
    "mean_f1_by_model = model_rankings.groupby('Model')['F1'].mean().sort_values(ascending=True)\n",
    "plt.subplot(1, 3, 3)\n",
    "bars = plt.barh(mean_f1_by_model.index, mean_f1_by_model, color='salmon')\n",
    "plt.title('APr≈Ømƒõrn√© F1 sk√≥re podle model≈Ø')\n",
    "plt.xlabel('F1')\n",
    "# Annotate exact average F1 scores\n",
    "for bar, score in zip(bars, mean_f1_by_model):\n",
    "    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{score:.4f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f1d1b0",
   "metadata": {},
   "source": [
    "## Generate shap for specific models and subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print all items in top3_models\n",
    "#for key, value in top3_models.items():\n",
    "    #print(key, value)\n",
    "    \n",
    "#subset = 'rdap_'\n",
    "\n",
    "prefixes = [\"lex_\"]\n",
    "\n",
    "for prefix in prefixes:\n",
    "\n",
    "    # Initialize SHAP explainer\n",
    "    explainer = shap.TreeExplainer(top3_models[prefix][0])\n",
    "\n",
    "    # Compute SHAP values\n",
    "    X = subset_dfs[prefix].drop('label', axis=1)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # Summary plot (beeswarm)\n",
    "    print(\"Using prefix: \", prefix)\n",
    "    shap.summary_plot(shap_values, X)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
